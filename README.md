
---

## **Modelos implementados**

###  **1. Modelo base (CNN desde cero)**
- Arquitectura simple con tres bloques convolucionales
- Entrada: 150150
- Aumento de datos b谩sico
- Optimizador: Adam (1e-4)

**Precisi贸n final:** ~0.76  
Servi贸 como punto de partida para el resto del proyecto.

---

###  **2. Modelo ajustado (CNN optimizada)**
- Resoluci贸n aumentada a 224224  
- Capas **Batch Normalization** en todos los bloques  
- Inclusi贸n de un **SE Block (Squeeze-and-Excitation)**  
- Regularizaci贸n con Dropout del 50%  
- Callbacks: EarlyStopping + ReduceLROnPlateau  

**Precisi贸n final:** ~0.88  
Mejor estabilidad y mejor capacidad de generalizaci贸n.

---

### **3. Transfer Learning con MobileNetV2 (modelo final)**
- MobileNetV2 preentrenada en ImageNet  
- Fase 1: Feature extraction con la base congelada  
- Fase 2: Fine-tuning de las 煤ltimas capas  
- Aumento de datos y preprocesamiento acorde al modelo  
- Clasificador denso de 256 neuronas

**Precisi贸n final:** **0.92**  
Mejor desempe帽o global y menor tasa de error por clase.

Este modelo es el utilizado en la entrega final.

---

## **Resultados generales**

| Modelo                  | Accuracy |
|-------------------------|----------|
| Modelo base             | 0.76     |
| Modelo ajustado         | 0.88     |
| Transfer Learning (TL)  | **0.92** |

El uso de **Transfer Learning** permiti贸 una mejora significativa en el rendimiento sin necesidad de entrenar millones de par谩metros desde cero.

---

## **Modelos entrenados**

Debido a su tama帽o, los modelos `.keras` **no se incluyen directamente en el repositorio**.  
Puedes descargarlos desde el siguiente enlace:

 **[Enlace de descarga del modelo final (model_tl2.keras)](URL_AQU)**  
*(https://drive.google.com/drive/folders/1x7pUkJoCLf4zFFfLkQnGt5pLG5oY6562?usp=sharing)*







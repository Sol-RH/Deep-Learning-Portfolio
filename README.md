
---

## ğŸ§  **Modelos implementados**

### ğŸ”¹ **1. Modelo base (CNN desde cero)**
- Arquitectura simple con tres bloques convolucionales
- Entrada: 150Ã—150
- Aumento de datos bÃ¡sico
- Optimizador: Adam (1e-4)

**PrecisiÃ³n final:** ~0.76  
ServiÃ³ como punto de partida para el resto del proyecto.

---

### ğŸ”¹ **2. Modelo ajustado (CNN optimizada)**
- ResoluciÃ³n aumentada a 224Ã—224  
- Capas **Batch Normalization** en todos los bloques  
- InclusiÃ³n de un **SE Block (Squeeze-and-Excitation)**  
- RegularizaciÃ³n con Dropout del 50%  
- Callbacks: EarlyStopping + ReduceLROnPlateau  

**PrecisiÃ³n final:** ~0.88  
Mejor estabilidad y mejor capacidad de generalizaciÃ³n.

---

### ğŸ”¹ **3. Transfer Learning con MobileNetV2 (modelo final)**
- MobileNetV2 preentrenada en ImageNet  
- Fase 1: Feature extraction con la base congelada  
- Fase 2: Fine-tuning de las Ãºltimas capas  
- Aumento de datos y preprocesamiento acorde al modelo  
- Clasificador denso de 256 neuronas

**PrecisiÃ³n final:** **0.92**  
Mejor desempeÃ±o global y menor tasa de error por clase.

Este modelo es el utilizado en la entrega final.

---

## ğŸ“Š **Resultados generales**

| Modelo                  | Accuracy |
|-------------------------|----------|
| Modelo base             | 0.76     |
| Modelo ajustado         | 0.88     |
| Transfer Learning (TL)  | **0.92** |

El uso de **Transfer Learning** permitiÃ³ una mejora significativa en el rendimiento sin necesidad de entrenar millones de parÃ¡metros desde cero.

---

## ğŸ“¦ **Modelos entrenados**

Debido a su tamaÃ±o, los modelos `.keras` **no se incluyen directamente en el repositorio**.  
Puedes descargarlos desde el siguiente enlace:

ğŸ”— **[Enlace de descarga del modelo final (MobileNetV2 Fine-Tuned)](URL_AQUÃ)**  
*(Reemplaza â€œURL_AQUÃâ€ con tu enlace real.)*






